{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUnelwesxIZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8fd1a3-3069-427b-97a9-256feb9c933f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ],
      "source": [
        "# Libary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "import zipfile\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#!pip install scikit-learn-intelex -q --progress-bar off\n",
        "#from sklearnex import patch_sklearn\n",
        "#patch_sklearn()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Dataset preparation\n"
      ],
      "metadata": {
        "id": "gG6slI3grT_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Download dataset\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1Brk0WwZ9ErOdyHTtOEP9-NlXHSI9ieB8'\n",
        "\n",
        "# Path where you want to save the downloaded file\n",
        "output = 'DoHBrw-2020.zip'\n",
        "\n",
        "# Download the file\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "5HHc9ps00ePa",
        "outputId": "cb795c26-43da-4e69-9710-aae441b16821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Brk0WwZ9ErOdyHTtOEP9-NlXHSI9ieB8\n",
            "From (redirected): https://drive.google.com/uc?id=1Brk0WwZ9ErOdyHTtOEP9-NlXHSI9ieB8&confirm=t&uuid=529d4d02-c34b-400e-84be-5826b4401643\n",
            "To: /content/DoHBrw-2020.zip\n",
            "100%|██████████| 808M/808M [00:15<00:00, 51.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DoHBrw-2020.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset\n",
        "with zipfile.ZipFile('DoHBrw-2020.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall()\n",
        "\n",
        "with zipfile.ZipFile('CSVs/Total_CSVs.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ],
      "metadata": {
        "id": "yliTtgKC07jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waptcXDDBc6T"
      },
      "outputs": [],
      "source": [
        "## Load dataset for learning\n",
        "file_paths = ['l1-doh.csv', 'l1-nondoh.csv', 'l2-benign.csv', 'l2-malicious.csv']\n",
        "\n",
        "# Read each CSV file into separate DataFrames\n",
        "dfs = [pd.read_csv(file) for file in file_paths]\n",
        "\n",
        "# Concatenate the DataFrames into a single DataFrame\n",
        "data = pd.concat(dfs, ignore_index=True)\n",
        "data = data.drop_duplicates()\n",
        "data = data.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520237ba-6744-4a2f-9d5d-cc69e66c8dc9",
        "id": "rUJE_FHt8TjZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features:  35\n"
          ]
        }
      ],
      "source": [
        "# Number of features\n",
        "print('Number of features: ',data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aaa5141-7b0c-4b7b-dcd8-6a634857d87b",
        "id": "ecX-7foy8Tja"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record per class:\n",
            " Label\n",
            "Benign        19807\n",
            "DoH          269643\n",
            "Malicious    249836\n",
            "NonDoH       897493\n",
            "dtype: int64\n",
            "\n",
            "Sum:\t\t 1436779\n"
          ]
        }
      ],
      "source": [
        "# Record per class\n",
        "print('Record per class:\\n',data.groupby('Label').size())\n",
        "print('\\nSum:\\t\\t',data['Label'].size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MFM8wmg-9uZ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Dataset preparation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmsEUc-i_abQ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "008ADU5S-9uZ"
      },
      "outputs": [],
      "source": [
        "# Encode categorical variables into numeric values\n",
        "labels = data['Label'].unique()\n",
        "label_encoders = {}\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    label_encoders[column] = LabelEncoder()\n",
        "    data[column] = data[column].astype(str)\n",
        "    data[column] = label_encoders[column].fit_transform(data[column])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['Label'])\n",
        "y = label_encoders['Label'].inverse_transform(data['Label'])"
      ],
      "metadata": {
        "id": "qRsH4PKgA-Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of train features: ',X.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPCsA70apdVs",
        "outputId": "80a0b14d-d2dd-4f20-ba70-29688d7d1a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train features:  34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR4jvbmEA9KA"
      },
      "outputs": [],
      "source": [
        "## Scaling and standardlize\n",
        "scaler = MinMaxScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76XQ1mwm_iFb"
      },
      "source": [
        "\n",
        "Data preprocessing\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI16ddX_9oNn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Feature selecttion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob7e_E6E9oNt"
      },
      "outputs": [],
      "source": [
        "def initialize_population(size, num_features, chromo_len):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        chromosome = np.random.choice(num_features, size=chromo_len, replace=False)\n",
        "        population.append(chromosome)\n",
        "    return np.array(population)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9LQTFK79oNt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def compute_fitness(population, X, y):\n",
        "    fitness_values = []\n",
        "    kf=KFold(shuffle=True)\n",
        "    for chromosome in population:\n",
        "        # Accuracy\n",
        "        Xfs = X.iloc[:,chromosome]\n",
        "\n",
        "        accuracy = cross_val_score(LogisticRegression(), X, y, cv=KFold(), scoring='accuracy').mean()\n",
        "\n",
        "        # Correlation matrix\n",
        "        corr_matrix = np.corrcoef(Xfs, rowvar=False)\n",
        "        corr_matrix = pd.DataFrame(corr_matrix).fillna(0).to_numpy()\n",
        "\n",
        "        # Correlation transform\n",
        "        corr_t_avg = 1 - abs((np.sum(corr_matrix) - np.trace(corr_matrix)) / (corr_matrix.size - corr_matrix.shape[0]))\n",
        "\n",
        "        fitness_values.append((accuracy + corr_t_avg) / 2)\n",
        "\n",
        "    return fitness_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGHTh8CI9oNt"
      },
      "outputs": [],
      "source": [
        "def parents_selection(population, fitness_values):\n",
        "    total_fitness = np.sum(fitness_values)\n",
        "    # Calculate selection probabilities for each chromosome\n",
        "    selection_probabilities = fitness_values / total_fitness\n",
        "    # Perform roulette wheel selection\n",
        "    selected_indices = np.random.choice(np.arange(len(population)), size=len(population), p=selection_probabilities)\n",
        "    # Select the chromosomes based on the selected indices\n",
        "    selected_parents = population[selected_indices]\n",
        "    return selected_parents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPmIfGjq9oNt"
      },
      "outputs": [],
      "source": [
        "def crossover(parents, crossover_rate=0.5):\n",
        "    num_parents = parents.shape[0]\n",
        "    num_genes = parents.shape[1]\n",
        "    offspring = np.empty_like(parents)\n",
        "    for i in range(num_parents):\n",
        "        # Select two parents for crossover\n",
        "        parent1 = parents[i]\n",
        "        parent2 = parents[(i + 1) % num_parents]\n",
        "        # Create a child chromosome\n",
        "        child = np.empty(num_genes)\n",
        "        cross_g = int(num_genes * crossover_rate)\n",
        "        # Copy the second half of parent1 to first half of child\n",
        "        child[:cross_g] = parent1[cross_g:]\n",
        "        # Copy (num_genes - cross_g) genes from parent2 that different from first half of child to the second half\n",
        "        child[cross_g:] = [e for e in parent2 if e not in child[:cross_g]][:(num_genes - cross_g)]\n",
        "        # Add the child to the offspring\n",
        "        offspring[i] = child\n",
        "    return offspring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIoku8f49oNt"
      },
      "outputs": [],
      "source": [
        "def mutation(parents, num_features, mutation_rate=0.5):\n",
        "    num_parents = parents.shape[0]\n",
        "    num_genes = parents.shape[1]\n",
        "    offspring = np.empty_like(parents)\n",
        "    mutate_g = int(num_genes * mutation_rate)\n",
        "    for i in range(num_parents):\n",
        "        child = np.empty(num_genes)\n",
        "\n",
        "        # Half first\n",
        "        s = 0\n",
        "        a = []\n",
        "        for j in range(num_genes):\n",
        "            s+=mutation_rate\n",
        "            if int(s)==1:\n",
        "                a.append(parents[i][j])\n",
        "                s-=1\n",
        "        child[:mutate_g] = a\n",
        "\n",
        "        # Half second\n",
        "        child[mutate_g:] =  np.random.choice(np.setdiff1d(np.arange(num_features), child),\n",
        "                                             size=num_genes-mutate_g, replace=False)\n",
        "\n",
        "        # Add the mutated child to the offspring\n",
        "        offspring[i] = child\n",
        "    return offspring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaLvvxbz9oNt"
      },
      "outputs": [],
      "source": [
        "def generations(X, y, pop_size, chromo_len,\n",
        "                mutation_rate=0.5, crossover_rate=0.5):\n",
        "    population = initialize_population(size=pop_size, num_features=X.shape[1], chromo_len=chromo_len)\n",
        "    fitness_values = compute_fitness(population=population, X=X, y=y)\n",
        "\n",
        "    mf_g = np.max(fitness_values)\n",
        "    mf = mf_g\n",
        "    best_chromo_g = population[np.argmax(fitness_values)]\n",
        "    gen = 0\n",
        "    best_chromo = best_chromo_g\n",
        "\n",
        "    print(\"Max fitness of generation\", gen, \": \", mf_g)\n",
        "    mf_g = -1\n",
        "\n",
        "    while True:\n",
        "      gen += 1\n",
        "\n",
        "      selected_parents = parents_selection(population, fitness_values)\n",
        "      population = crossover(selected_parents, crossover_rate=crossover_rate)\n",
        "      fitness_values = compute_fitness(population=population, X=X, y=y)\n",
        "      if np.max(fitness_values) > mf_g:\n",
        "        mf_g = np.max(fitness_values)\n",
        "        best_chromo_g = population[np.argmax(fitness_values)]\n",
        "\n",
        "      selected_parents = parents_selection(population, fitness_values)\n",
        "      population = mutation(selected_parents, num_features=X.shape[1], mutation_rate=mutation_rate)\n",
        "      fitness_values = compute_fitness(population=population, X=X, y=y)\n",
        "      if np.max(fitness_values) > mf_g:\n",
        "        mf_g = np.max(fitness_values)\n",
        "        best_chromo_g = population[np.argmax(fitness_values)]\n",
        "\n",
        "      print(\"Max fitness of generation\", gen, \": \", mf_g)\n",
        "      if mf_g > mf:\n",
        "        mf = mf_g\n",
        "        best_chromo = best_chromo_g\n",
        "        mf_g = -1\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    return best_chromo, mf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbNsZc919oNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6394d57e-8406-4038-ac02-c52f86d5ec33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max fitness of generation 0 :  0.8096652034211411\n",
            "Max fitness of generation 1 :  0.8096618208992259\n",
            "Best feature:  ['PacketTimeStandardDeviation', 'FlowReceivedRate', 'PacketLengthSkewFromMode', 'SourcePort', 'SourceIP', 'TimeStamp', 'ResponseTimeTimeStandardDeviation', 'ResponseTimeTimeMedian', 'ResponseTimeTimeSkewFromMedian', 'PacketLengthMedian']\n",
            "Max fitness:  0.8096652034211411\n"
          ]
        }
      ],
      "source": [
        "best_chromo, max_fitness = generations(X=X, y=y, pop_size=100, chromo_len=10,\n",
        "                                       crossover_rate = 0.5, mutation_rate = 0.5)\n",
        "print(\"Best feature: \", list(X.columns[best_chromo]))\n",
        "print(\"Max fitness: \", max_fitness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_scv7A49oNt"
      },
      "source": [
        "Feature Selection\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best chromo\n",
        "np.save('Doh_best_chromo.npy', best_chromo)"
      ],
      "metadata": {
        "id": "Q6NUt_9zsr30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True: pass"
      ],
      "metadata": {
        "id": "5JLvCVbfY_8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}