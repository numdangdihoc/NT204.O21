{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUnelwesxIZA",
        "outputId": "a66351fa-3762-462a-d66d-2c645d9ff2d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ],
      "source": [
        "# Libary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "import zipfile\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#!pip install scikit-learn-intelex -q --progress-bar off\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG6slI3grT_5"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Dataset preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "5HHc9ps00ePa",
        "outputId": "7ab0a1a6-aa0d-488d-ec52-9d11bd130df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iUC1Pv-1JfYWUKMGZQ2xSOk0nYAM2f6i\n",
            "From (redirected): https://drive.google.com/uc?id=1iUC1Pv-1JfYWUKMGZQ2xSOk0nYAM2f6i&confirm=t&uuid=685347ce-041d-4ffd-ae31-b37d988107a0\n",
            "To: /content/UNSW_NB15.zip\n",
            "100%|██████████| 156M/156M [00:02<00:00, 52.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UNSW_NB15.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "## Download dataset\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1iUC1Pv-1JfYWUKMGZQ2xSOk0nYAM2f6i'\n",
        "\n",
        "# Path where you want to save the downloaded file\n",
        "output = 'UNSW_NB15.zip'\n",
        "\n",
        "# Download the file\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEZQX8FzwZJt"
      },
      "outputs": [],
      "source": [
        "# Unzip dataset\n",
        "with zipfile.ZipFile('UNSW_NB15.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvD8YZzu4Txu"
      },
      "outputs": [],
      "source": [
        "## Load dataset for learning\n",
        "# Encode problem\n",
        "import chardet\n",
        "with open('NUSW-NB15_features.csv', 'rb') as f:\n",
        "    encoding = chardet.detect(f.read())['encoding']\n",
        "\n",
        "# Get feature\n",
        "cols = list(pd.read_csv('NUSW-NB15_features.csv', encoding=encoding)['Name'])\n",
        "\n",
        "file_paths = ['UNSW-NB15_1.csv','UNSW-NB15_2.csv','UNSW-NB15_3.csv','UNSW-NB15_4.csv']\n",
        "\n",
        "# Read each CSV file into separate DataFrames\n",
        "dfs = [pd.read_csv(file, names=cols) for file in file_paths]\n",
        "\n",
        "# Concatenate the DataFrames into a single DataFrame\n",
        "data = pd.concat(dfs, ignore_index=True)\n",
        "data['attack_cat'] = data['attack_cat'].str.strip().str.replace('Backdoors', 'Backdoor')\n",
        "data['attack_cat'] = data['attack_cat'].fillna(value='Normal')\n",
        "data = data.drop_duplicates(ignore_index=True)\n",
        "data = data.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_class(df, cls_col, cls, cls_size):\n",
        "    resampled_dfs = [df[df[cls_col] != cls]]\n",
        "    cls_df = df[df[cls_col] == cls]\n",
        "    current_class_size = len(cls_df)\n",
        "\n",
        "    if current_class_size > cls_size:\n",
        "        # Undersample: Reduce the number of samples\n",
        "        cls_df_resampled = cls_df.sample(cls_size, random_state=42)\n",
        "    elif current_class_size < cls_size:\n",
        "        # Oversample: Increase the number of samples\n",
        "        cls_df_resampled = cls_df.sample(cls_size, replace=True, random_state=42)\n",
        "    else:\n",
        "        cls_df_resampled = cls_df\n",
        "\n",
        "    resampled_dfs.append(cls_df_resampled)\n",
        "\n",
        "    return pd.concat(resampled_dfs).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-x53y_PjDxLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = balance_class(data, 'attack_cat', 'Analysis', 677)\n",
        "data = balance_class(data, 'attack_cat', 'Backdoor', 577)\n",
        "data = balance_class(data, 'attack_cat', 'DoS', 4089)\n",
        "data = balance_class(data, 'attack_cat', 'Exploits', 7061)\n",
        "data = balance_class(data, 'attack_cat', 'Fuzzers', 12062)\n",
        "data = balance_class(data, 'attack_cat', 'Generic', 5016)\n",
        "data = balance_class(data, 'attack_cat', 'Normal', 31395)\n",
        "data = balance_class(data, 'attack_cat', 'Reconnaissance', 1695)\n",
        "data = balance_class(data, 'attack_cat', 'Shellcode', 378)\n",
        "data = balance_class(data, 'attack_cat', 'Worms', 44)"
      ],
      "metadata": {
        "id": "KvugBLo0Dx2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LGN15M7cOl9",
        "outputId": "f3832d80-2d21-4c05-cb39-c0c3ad19f098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features:  49\n"
          ]
        }
      ],
      "source": [
        "# Number of features\n",
        "print('Number of features: ',data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_mtPL7oH2fe",
        "outputId": "bf2594b7-986c-4af8-93d4-29303ef26a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record per class:\n",
            " attack_cat\n",
            "Analysis            677\n",
            "Backdoor            577\n",
            "DoS                4089\n",
            "Exploits           7061\n",
            "Fuzzers           12062\n",
            "Generic            5016\n",
            "Normal            31395\n",
            "Reconnaissance     1695\n",
            "Shellcode           378\n",
            "Worms                44\n",
            "dtype: int64\n",
            "\n",
            "Sum:\t\t 62994\n"
          ]
        }
      ],
      "source": [
        "# Record per class\n",
        "print('Record per class:\\n',data.groupby('attack_cat').size())\n",
        "print('\\nSum:\\t\\t',data['attack_cat'].size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFs32DI2rhaL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Dataset preparation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmsEUc-i_abQ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwEPCQ-t8aFq"
      },
      "outputs": [],
      "source": [
        "# Encode categorical variables into numeric values\n",
        "labels = data['attack_cat'].unique()\n",
        "label_encoders = {}\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    label_encoders[column] = LabelEncoder()\n",
        "    data[column] = data[column].astype(str)\n",
        "    data[column] = label_encoders[column].fit_transform(data[column])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['attack_cat', 'Label'],axis=1)\n",
        "y = data['attack_cat']\n",
        "y = label_encoders['attack_cat'].inverse_transform(y)"
      ],
      "metadata": {
        "id": "qRsH4PKgA-Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of train features: ',X.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSotTiFepUlI",
        "outputId": "db9e2324-c8f3-48ad-c675-e6d48f321426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train features:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR4jvbmEA9KA"
      },
      "outputs": [],
      "source": [
        "## Scaling and standardlize\n",
        "scaler = MinMaxScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76XQ1mwm_iFb"
      },
      "source": [
        "\n",
        "Data preprocessing\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xhWjfXdAVyh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Feature selecttion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOBGlwKqA_Rt"
      },
      "outputs": [],
      "source": [
        "def initialize_population(size, num_features, chromo_len):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        chromosome = np.random.choice(num_features, size=chromo_len, replace=False)\n",
        "        population.append(chromosome)\n",
        "    return np.array(population)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGVOuH4vDXCi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def compute_fitness(population, X, y):\n",
        "    fitness_values = []\n",
        "    kf=KFold(shuffle=True)\n",
        "    for chromosome in population:\n",
        "        # Accuracy\n",
        "        Xfs = X.iloc[:,chromosome]\n",
        "\n",
        "        accuracy = cross_val_score(LogisticRegression(), X, y, cv=KFold(), scoring='accuracy').mean()\n",
        "\n",
        "        # Correlation matrix\n",
        "        corr_matrix = np.corrcoef(Xfs, rowvar=False)\n",
        "        corr_matrix = pd.DataFrame(corr_matrix).fillna(0).to_numpy()\n",
        "\n",
        "        # Correlation transform\n",
        "        corr_t_avg = 1 - abs((np.sum(corr_matrix) - np.trace(corr_matrix)) / (corr_matrix.size - corr_matrix.shape[0]))\n",
        "\n",
        "        fitness_values.append((accuracy + corr_t_avg) / 2)\n",
        "\n",
        "    return fitness_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPaegOI4LwgN"
      },
      "outputs": [],
      "source": [
        "def parents_selection(population, fitness_values):\n",
        "    total_fitness = np.sum(fitness_values)\n",
        "    # Calculate selection probabilities for each chromosome\n",
        "    selection_probabilities = fitness_values / total_fitness\n",
        "    # Perform roulette wheel selection\n",
        "    selected_indices = np.random.choice(np.arange(len(population)), size=len(population), p=selection_probabilities)\n",
        "    # Select the chromosomes based on the selected indices\n",
        "    selected_parents = population[selected_indices]\n",
        "    return selected_parents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIpR644zN2SB"
      },
      "outputs": [],
      "source": [
        "def crossover(parents, crossover_rate=0.5):\n",
        "    num_parents = parents.shape[0]\n",
        "    num_genes = parents.shape[1]\n",
        "    offspring = np.empty_like(parents)\n",
        "    cross_g = int(num_genes * crossover_rate)\n",
        "    for i in range(num_parents):\n",
        "        # Select two parents for crossover\n",
        "        parent1 = parents[i]\n",
        "        parent2 = parents[(i + 1) % num_parents]\n",
        "        # Create a child chromosome\n",
        "        child = np.empty(num_genes)\n",
        "        # Copy the second half of parent1 to first half of child\n",
        "        child[:cross_g] = parent1[cross_g:]\n",
        "        # Copy (num_genes - cross_g) genes from parent2 that different from first half of child to the second half\n",
        "        child[cross_g:] = [e for e in parent2 if e not in child[:cross_g]][:(num_genes - cross_g)]\n",
        "        # Add the child to the offspring\n",
        "        offspring[i] = child\n",
        "    return offspring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFlBKyEgPDYW"
      },
      "outputs": [],
      "source": [
        "def mutation(parents, num_features, mutation_rate=0.5):\n",
        "    num_parents = parents.shape[0]\n",
        "    num_genes = parents.shape[1]\n",
        "    offspring = np.empty_like(parents)\n",
        "    mutate_g = int(num_genes * mutation_rate)\n",
        "    for i in range(num_parents):\n",
        "        child = np.empty(num_genes)\n",
        "\n",
        "        # Half first\n",
        "        s = 0\n",
        "        a = []\n",
        "        for j in range(num_genes):\n",
        "            s+=mutation_rate\n",
        "            if int(s)==1:\n",
        "                a.append(parents[i][j])\n",
        "                s-=1\n",
        "        child[:mutate_g] = a\n",
        "\n",
        "        # Half second\n",
        "        child[mutate_g:] =  np.random.choice(np.setdiff1d(np.arange(num_features), child),\n",
        "                                             size=num_genes-mutate_g, replace=False)\n",
        "\n",
        "        # Add the mutated child to the offspring\n",
        "        offspring[i] = child\n",
        "    return offspring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9YlOu7rriKu"
      },
      "outputs": [],
      "source": [
        "def generations(X, y, pop_size, chromo_len,\n",
        "                mutation_rate=0.5, crossover_rate=0.5):\n",
        "    population = initialize_population(size=pop_size, num_features=X.shape[1], chromo_len=chromo_len)\n",
        "    fitness_values = compute_fitness(population=population, X=X, y=y)\n",
        "\n",
        "    mf_g = np.max(fitness_values)\n",
        "    mf = mf_g\n",
        "    best_chromo_g = population[np.argmax(fitness_values)]\n",
        "    gen = 0\n",
        "    best_chromo = best_chromo_g\n",
        "\n",
        "    print(\"Max fitness of generation\", gen, \": \", mf_g)\n",
        "    mf_g = -1\n",
        "\n",
        "    while True:\n",
        "      gen += 1\n",
        "\n",
        "      selected_parents = parents_selection(population, fitness_values)\n",
        "      population = crossover(selected_parents, crossover_rate=crossover_rate)\n",
        "      fitness_values = compute_fitness(population=population, X=X, y=y)\n",
        "      if np.max(fitness_values) > mf_g:\n",
        "        mf_g = np.max(fitness_values)\n",
        "        best_chromo_g = population[np.argmax(fitness_values)]\n",
        "\n",
        "      selected_parents = parents_selection(population, fitness_values)\n",
        "      population = mutation(selected_parents, num_features=X.shape[1], mutation_rate=mutation_rate)\n",
        "      fitness_values = compute_fitness(population=population, X=X, y=y)\n",
        "      if np.max(fitness_values) > mf_g:\n",
        "        mf_g = np.max(fitness_values)\n",
        "        best_chromo_g = population[np.argmax(fitness_values)]\n",
        "\n",
        "      print(\"Max fitness of generation\", gen, \": \", mf_g)\n",
        "      if mf_g > mf:\n",
        "        mf = mf_g\n",
        "        best_chromo = best_chromo_g\n",
        "        mf_g = -1\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    return best_chromo, mf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_chromo, max_fitness = generations(X=X, y=y, pop_size=100, chromo_len=10,\n",
        "                                       crossover_rate = 0.5, mutation_rate = 0.5)\n",
        "print(\"Best feature: \", list(X.columns[best_chromo]))\n",
        "print(\"Max fitness: \", max_fitness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu-EIg8gKFY_",
        "outputId": "7b43d72b-e7b6-4f4e-eb5a-ccaddcebd3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max fitness of generation 0 :  0.7737636077004644\n",
            "Max fitness of generation 1 :  0.7742008979204442\n",
            "Max fitness of generation 2 :  0.7741007003088096\n",
            "Best feature:  ['Dintpkt', 'dmeansz', 'dttl', 'ct_dst_ltm', 'srcip', 'ct_state_ttl', 'synack', 'dbytes', 'dur', 'ct_dst_sport_ltm']\n",
            "Max fitness:  0.7742008979204442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qTlbLiOAaxa"
      },
      "source": [
        "Feature Selection\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best chromo\n",
        "np.save('UNSW_best_chromo.npy', best_chromo)"
      ],
      "metadata": {
        "id": "-JGXeGJnMelG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-VtXjk8631V"
      },
      "outputs": [],
      "source": [
        "while True: pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}